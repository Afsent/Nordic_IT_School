{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам дан файл `ru.conversations.txt`\n",
    "\n",
    "В нем содержатся диалоги (разделены пустой строкой).\n",
    "\n",
    "Вам необходимо:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбить текст на диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('ru.conversations.txt', 'r', encoding='utf-8') as f:\n",
    "    text = []\n",
    "    for line in f:\n",
    "        text.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- Что,  Мансур,  не жарко теперь тебе?\\n',\n",
       " '- Спрашиваю, не жарко ему теперь?\\n',\n",
       " '\\n',\n",
       " '- Какой полк?\\n',\n",
       " '- Тысяча тридцать четвертый.\\n',\n",
       " '- Вези дальше. Тут тысяча двадцать шестой.\\n',\n",
       " '\\n',\n",
       " '- Какая санрота?\\n',\n",
       " '- Тысяча тридцать шестая.\\n',\n",
       " '- Значит, наша! Принимай тяжелораненого!\\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- Что,  Мансур,  не жарко теперь тебе?\\n- Спрашиваю, не жарко ему теперь?\\n', '- Какой полк?\\n- Тысяча тридцать четвертый.\\n- Вези дальше. Тут тысяча двадцать шестой.\\n', '- Какая санрота?\\n- Тысяча тридцать шестая.\\n- Значит, наша! Принимай тяжелораненого!\\n', '- Сколько фрицев в котле?\\n- Тысяч сорок.\\n', '- Чем же он отравился?\\n- А вон, видишь, что-то из тех бутылей выпил.\\n']\n"
     ]
    }
   ],
   "source": [
    "dialogs = []\n",
    "dialog = ''\n",
    "for item in text:\n",
    "    if item != '\\n':\n",
    "        dialog += item\n",
    "    else:\n",
    "        dialogs.append(dialog)\n",
    "        dialog = ''\n",
    "print(dialogs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбить диалоги на токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pro10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,item in enumerate(dialogs):\n",
    "    dialogs[i] = word_tokenize(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработать токены\n",
    "Удалить стоп-слова и спецсимволы, лемматизировать или стеммировать слова и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pro10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for i,item in enumerate(dialogs):\n",
    "    dialogs[i] = tokenizer.tokenize(str(dialogs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dialogs = dialogs\n",
    "for i, dialog in enumerate(dialogs):\n",
    "    clean_dialog = dialog\n",
    "    for word in dialog:\n",
    "        if word.lower() in stopwords.words('russian'):\n",
    "            clean_dialog.remove(word)\n",
    "    clean_dialogs[i] = clean_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Мансур', 'жарко', 'тебе', 'Спрашиваю', 'жарко', 'теперь'],\n",
       " ['полк',\n",
       "  'Тысяча',\n",
       "  'тридцать',\n",
       "  'четвертый',\n",
       "  'Вези',\n",
       "  'дальше',\n",
       "  'тысяча',\n",
       "  'двадцать',\n",
       "  'шестой'],\n",
       " ['санрота',\n",
       "  'Тысяча',\n",
       "  'тридцать',\n",
       "  'шестая',\n",
       "  'Значит',\n",
       "  'наша',\n",
       "  'Принимай',\n",
       "  'тяжелораненого'],\n",
       " ['Сколько', 'фрицев', 'котле', 'Тысяч', 'сорок'],\n",
       " ['же', 'отравился', 'вон', 'видишь', 'то', 'тех', 'бутылей', 'выпил']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dialogs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "rus_stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_dialogs = clean_dialogs\n",
    "for i, dialog in enumerate(clean_dialogs):\n",
    "    stem_dialog = dialog\n",
    "    for j, word in enumerate(dialog):\n",
    "        stem_dialog[j] = rus_stemmer.stem(word)\n",
    "    stem_dialogs[i] = stem_dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перевести каждый из диалогов в векторное представление\n",
    "\n",
    "С помощью TF-IDF представить каждый из диалогов в векторном формате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [' '.join(map(str, stem_dialogs[i])) for i in range(len(stem_dialogs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мансур жарк теб спрашива жарк тепер',\n",
       " 'полк тысяч тридца четверт вез дальш тысяч двадца шест',\n",
       " 'санрот тысяч тридца шест знач наш принима тяжелоранен',\n",
       " 'скольк фриц котл тысяч сорок',\n",
       " 'же отрав вон вид то тех бутыл вып',\n",
       " 'что мансур дел фашист прорва оборон мы тоб спим',\n",
       " 'их гумрак',\n",
       " 'комсорг не прот ещ сто',\n",
       " 'брал во',\n",
       " 'мансур ты сбил может нибуд стреля']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfvec = txt.TfidfVectorizer()\n",
    "vect = tfvec.fit_transform(strings[:1000]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найти самые близкие по содержанию диалоги, исходя из векторного представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclid = []\n",
    "for i in range(1000):\n",
    "    for j in range(i):\n",
    "        euclid.append((i,j, euclidean(vect[i], vect[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 22, 0.0),\n",
       " (660, 659, 0.0),\n",
       " (732, 113, 0.0),\n",
       " (548, 547, 0.39714431308522974),\n",
       " (571, 434, 0.5076919943988746),\n",
       " (625, 603, 0.5399726721243513),\n",
       " (293, 156, 0.5740216055422772),\n",
       " (663, 69, 0.6632243265416782),\n",
       " (202, 159, 0.7027577435761159),\n",
       " (943, 526, 0.7150294095118789)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = sorted(euclid, key=lambda x: x[2])[:10]\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index0 = [item[0] for item in top]\n",
    "index1 = [item[1] for item in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "плох наш дел над идт ~ плох наш дел над идт\n",
      "кажет ошиб то провер да ~ кажет ошиб то провер да\n",
      "что нич ~ что нич\n",
      "знает вы майор шелл знает вы майор онезорг ~ знает вы майор шелл знает вы капита онезорг\n",
      "кто говор говор ~ говор говор говор\n",
      "неужел эт правд правд ~ правд эт правд что эт\n",
      "нашл ~ как нашл клад нашл\n",
      "ясн товарищ капита товарищ капита товарищ капита как будут указан никак по самолет ~ я товарищ капита\n",
      "разреш нача начина ~ разреш начина начина\n",
      "понятн понятн вам понятн фашист бок правильн ~ понятн глущенк понятн\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(index0,index1):\n",
    "        print(strings[i], '~', strings[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs = []\n",
    "dialog = ''\n",
    "for item in text:\n",
    "    if item != '\\n':\n",
    "        dialog += item\n",
    "    else:\n",
    "        dialogs.append(dialog)\n",
    "        dialog = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Плохо наше дело.\n",
      "- Опять надо идти?\n",
      " ~~~~~~~\n",
      " - Плохо наше дело.\n",
      "- Опять надо идти?\n",
      "\n",
      "- Я кажется ошибся где-то.\n",
      "- А проверить можно?\n",
      "- Да,  конечно.\n",
      " ~~~~~~~\n",
      " - Я кажется ошибся где-то.\n",
      "- А проверить можно?\n",
      "- Да,  конечно.\n",
      "\n",
      "- Ну, что там?\n",
      "- Ничего.\n",
      " ~~~~~~~\n",
      " - Есть что-нибудь?\n",
      "- Ничего.\n",
      "\n",
      "- Знаете ли вы майора Шелла?\n",
      "- Нет.\n",
      "- Знаете ли вы майора Онезорге?\n",
      "- Нет.\n",
      " ~~~~~~~\n",
      " - Знаете ли вы майора Шелла?\n",
      "- Нет.\n",
      "- Знаете ли вы капитана Онезорге?\n",
      "- Нет.\n",
      "\n",
      "- А кто говорит?\n",
      "- Все говорят!\n",
      " ~~~~~~~\n",
      " - Ну,  говори же, говори!\n",
      "- Говорить надо?\n",
      "\n",
      "- Да неужели это правда?\n",
      "- Да, правда.\n",
      " ~~~~~~~\n",
      " - Правда ли это?\n",
      "- Правда.\n",
      "- Ну  что  же,  это  хорошо.\n",
      "\n",
      "- Нашли?\n",
      "- Нет!..\n",
      " ~~~~~~~\n",
      " - Ну как, нашли клад?\n",
      "- Нашли.\n",
      "\n",
      "- Ясно, товарищ капитан.\n",
      "- Товарищ  капитан.\n",
      "- Есть, товарищ капитан.\n",
      "- Какие будут еще указания?\n",
      "- Больше никаких.\n",
      "- Тогда  по  самолетам.\n",
      " ~~~~~~~\n",
      " - Кто?\n",
      "- Я,товарищ капитан!\n",
      "\n",
      "- Разрешите начать?\n",
      "- Начинайте!\n",
      " ~~~~~~~\n",
      " - Разрешите начинать?\n",
      "- Начинайте!\n",
      "\n",
      "- Понятно?\n",
      "- Понятно.\n",
      "- Что вам понятно?\n",
      "- Фашисты под боком.\n",
      "- Правильно.\n",
      " ~~~~~~~\n",
      " - Понятно, Глущенко?\n",
      "- Понятно.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(index0,index1):\n",
    "        print(dialogs[i], '~~~~~~~\\n', dialogs[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
